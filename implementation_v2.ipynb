{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import v2 as trans2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Datasets and setup the Data Loaders (with data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_normal = transforms.Compose([\n",
    "    transforms.Resize((250, 250)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((250, 250)),\n",
    "    # Randomly change the brightness of the image\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    # Randomly flip the image horizontally\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),  # Randomly flip the image vertically\n",
    "    transforms.RandomRotation(55),  # Randomly rotate the image by 45 degrees\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean = mean, std = std) # Takes each value for the channel, subtracts the mean and divides by the standard deviation (value - mean) / std\n",
    "])\n",
    "\n",
    "# Define the transformations\n",
    "transformations1 = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Resize((250, 250))])\n",
    "\n",
    "# Load the dataset\n",
    "training_dataset = torchvision.datasets.Flowers102(root='./data', split=\"train\",\n",
    "                                                   download=True, transform=transform_train)\n",
    "testing_dataset = torchvision.datasets.Flowers102(root='./data', split=\"test\",\n",
    "                                                  download=True, transform=transformations1)\n",
    "validation_dataset = torchvision.datasets.Flowers102(root='./data', split=\"val\",\n",
    "                                                     download=True, transform=transformations1)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.relu = nn.PReLU()\n",
    "    \n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer4 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer5 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer6 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    \n",
    "    # self.fc1 = nn.Linear(256 * 3 * 3, 1024)\n",
    "    self.fc1 = nn.Linear(256 * 3 * 3, 1024)\n",
    "    self.drop = nn.Dropout(p=0.5)\n",
    "    self.fc2 = nn.Linear(1024, 256)\n",
    "    self.fc3 = nn.Linear(256, 102)  # Output layer for 102 classes\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "    x = self.layer5(x)\n",
    "    x = self.layer6(x)\n",
    "    \n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    x = self.drop(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.drop(x)\n",
    "    x = self.fc3(x)\n",
    "    # x = self.drop(x)\n",
    "    # x = self.fc2(x)\n",
    "    # x = self.relu(x)\n",
    "    # x = self.fc3(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=8)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Accuracy Tests (Validation and Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NetworkAccuracyOnValidation():\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # num_class_correct = [0 for i in range(102)]\n",
    "        # num_class_samples = [0 for i in range(102)]\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for images, labels in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # for i in range(len(labels)):\n",
    "            #     label = labels[i]\n",
    "            #     pred = predictions[i]\n",
    "            #     if label == pred:\n",
    "            #         num_class_correct[label] += 1\n",
    "            #     num_class_samples[label] += 1\n",
    "\n",
    "    val_epoch_loss = val_loss / val_total\n",
    "    val_epoch_acc = 100. * val_correct / val_total\n",
    "    \n",
    "    return val_epoch_loss, val_epoch_acc\n",
    "\n",
    "def NetworkAccuracyOnTesting():\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    num_class_correct = [0] * 102\n",
    "    num_class_samples = [0] * 102\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predictions = outputs.max(1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += predictions.eq(labels).sum().item()\n",
    "            \n",
    "            c = (predictions == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                num_class_correct[label] += c[i].item()\n",
    "                num_class_samples[label] += 1\n",
    "\n",
    "            # for i in range(len(labels)):\n",
    "            #     label = labels[i]\n",
    "            #     pred = predictions[i]\n",
    "            #     if (label == pred):\n",
    "            #         num_class_correct[label] += 1\n",
    "            #     num_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * total_correct / total_samples\n",
    "    print(f'Accuracy on testing set: {acc} %')\n",
    "\n",
    "    for i in range(102):\n",
    "        acc = 100.0 * num_class_correct[i] / num_class_samples[i]\n",
    "        print(f'Accuracy of {i} : {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250, Loss: 19.3096, Accuracy: 1.76%\n",
      "Validation Loss: 4.6255, Validation Accuracy: 1.86%\n",
      "Epoch 2/250, Loss: 19.0811, Accuracy: 2.06%\n",
      "Validation Loss: 4.5399, Validation Accuracy: 2.06%\n",
      "Epoch 3/250, Loss: 18.8083, Accuracy: 2.94%\n",
      "Validation Loss: 4.3557, Validation Accuracy: 4.02%\n",
      "Epoch 4/250, Loss: 18.5611, Accuracy: 3.33%\n",
      "Validation Loss: 4.2014, Validation Accuracy: 5.39%\n",
      "Epoch 5/250, Loss: 18.3123, Accuracy: 4.41%\n",
      "Validation Loss: 4.0845, Validation Accuracy: 8.82%\n",
      "Epoch 6/250, Loss: 18.1000, Accuracy: 5.98%\n",
      "Validation Loss: 4.0449, Validation Accuracy: 8.63%\n",
      "Epoch 7/250, Loss: 17.9143, Accuracy: 5.29%\n",
      "Validation Loss: 3.9594, Validation Accuracy: 11.96%\n",
      "Epoch 8/250, Loss: 17.7052, Accuracy: 6.08%\n",
      "Validation Loss: 3.9017, Validation Accuracy: 9.51%\n",
      "Epoch 9/250, Loss: 17.5219, Accuracy: 6.67%\n",
      "Validation Loss: 3.8685, Validation Accuracy: 12.25%\n",
      "Epoch 10/250, Loss: 17.3135, Accuracy: 6.47%\n",
      "Validation Loss: 3.8237, Validation Accuracy: 13.53%\n",
      "Epoch 11/250, Loss: 17.1250, Accuracy: 8.14%\n",
      "Validation Loss: 3.8177, Validation Accuracy: 14.80%\n",
      "Epoch 12/250, Loss: 16.9129, Accuracy: 8.73%\n",
      "Validation Loss: 3.7132, Validation Accuracy: 17.16%\n",
      "Epoch 13/250, Loss: 16.8296, Accuracy: 8.43%\n",
      "Validation Loss: 3.6719, Validation Accuracy: 15.20%\n",
      "Epoch 14/250, Loss: 16.6509, Accuracy: 8.73%\n",
      "Validation Loss: 3.6225, Validation Accuracy: 19.51%\n",
      "Epoch 15/250, Loss: 16.4445, Accuracy: 8.82%\n",
      "Validation Loss: 3.5748, Validation Accuracy: 19.31%\n",
      "Epoch 16/250, Loss: 16.2795, Accuracy: 10.78%\n",
      "Validation Loss: 3.5866, Validation Accuracy: 16.27%\n",
      "Epoch 17/250, Loss: 16.1255, Accuracy: 11.18%\n",
      "Validation Loss: 3.4571, Validation Accuracy: 19.22%\n",
      "Epoch 18/250, Loss: 15.9553, Accuracy: 11.86%\n",
      "Validation Loss: 3.4210, Validation Accuracy: 21.37%\n",
      "Epoch 19/250, Loss: 15.7813, Accuracy: 12.35%\n",
      "Validation Loss: 3.4295, Validation Accuracy: 20.29%\n",
      "Epoch 20/250, Loss: 15.6122, Accuracy: 13.24%\n",
      "Validation Loss: 3.3966, Validation Accuracy: 17.25%\n",
      "Epoch 21/250, Loss: 15.5025, Accuracy: 12.55%\n",
      "Validation Loss: 3.2973, Validation Accuracy: 21.57%\n",
      "Epoch 22/250, Loss: 15.3640, Accuracy: 14.02%\n",
      "Validation Loss: 3.3452, Validation Accuracy: 20.69%\n",
      "Epoch 23/250, Loss: 15.2023, Accuracy: 15.10%\n",
      "Validation Loss: 3.2354, Validation Accuracy: 24.02%\n",
      "Epoch 24/250, Loss: 15.0377, Accuracy: 15.49%\n",
      "Validation Loss: 3.1956, Validation Accuracy: 23.33%\n",
      "Epoch 25/250, Loss: 14.8502, Accuracy: 18.24%\n",
      "Validation Loss: 3.1617, Validation Accuracy: 25.39%\n",
      "Epoch 26/250, Loss: 14.7723, Accuracy: 18.14%\n",
      "Validation Loss: 3.1374, Validation Accuracy: 25.98%\n",
      "Epoch 27/250, Loss: 14.6415, Accuracy: 15.20%\n",
      "Validation Loss: 3.1670, Validation Accuracy: 23.14%\n",
      "Epoch 28/250, Loss: 14.5487, Accuracy: 18.53%\n",
      "Validation Loss: 3.1826, Validation Accuracy: 23.33%\n",
      "Epoch 29/250, Loss: 14.3952, Accuracy: 18.14%\n",
      "Validation Loss: 3.0738, Validation Accuracy: 27.75%\n",
      "Epoch 30/250, Loss: 14.2612, Accuracy: 20.88%\n",
      "Validation Loss: 3.1306, Validation Accuracy: 23.43%\n",
      "Epoch 31/250, Loss: 14.1999, Accuracy: 19.80%\n",
      "Validation Loss: 3.1483, Validation Accuracy: 22.94%\n",
      "Epoch 32/250, Loss: 14.0866, Accuracy: 20.88%\n",
      "Validation Loss: 3.0739, Validation Accuracy: 25.88%\n",
      "Epoch 33/250, Loss: 13.9226, Accuracy: 22.45%\n",
      "Validation Loss: 3.0467, Validation Accuracy: 25.39%\n",
      "Epoch 34/250, Loss: 13.8470, Accuracy: 20.88%\n",
      "Validation Loss: 2.9831, Validation Accuracy: 29.22%\n",
      "Epoch 35/250, Loss: 13.7696, Accuracy: 21.27%\n",
      "Validation Loss: 2.9340, Validation Accuracy: 29.12%\n",
      "Epoch 36/250, Loss: 13.6164, Accuracy: 23.14%\n",
      "Validation Loss: 2.9039, Validation Accuracy: 30.00%\n",
      "Epoch 37/250, Loss: 13.5279, Accuracy: 22.65%\n",
      "Validation Loss: 2.9216, Validation Accuracy: 27.84%\n",
      "Epoch 38/250, Loss: 13.4197, Accuracy: 23.92%\n",
      "Validation Loss: 2.9124, Validation Accuracy: 29.02%\n",
      "Epoch 39/250, Loss: 13.2711, Accuracy: 26.57%\n",
      "Validation Loss: 2.9554, Validation Accuracy: 27.06%\n",
      "Epoch 40/250, Loss: 13.2121, Accuracy: 24.51%\n",
      "Validation Loss: 2.8925, Validation Accuracy: 26.57%\n",
      "Epoch 41/250, Loss: 13.1006, Accuracy: 26.27%\n",
      "Validation Loss: 2.8576, Validation Accuracy: 29.80%\n",
      "Epoch 42/250, Loss: 12.9914, Accuracy: 29.61%\n",
      "Validation Loss: 2.8373, Validation Accuracy: 29.12%\n",
      "Epoch 43/250, Loss: 12.9220, Accuracy: 26.27%\n",
      "Validation Loss: 2.8639, Validation Accuracy: 28.63%\n",
      "Epoch 44/250, Loss: 12.8373, Accuracy: 26.76%\n",
      "Validation Loss: 2.7465, Validation Accuracy: 31.37%\n",
      "Epoch 45/250, Loss: 12.7527, Accuracy: 27.16%\n",
      "Validation Loss: 2.8082, Validation Accuracy: 30.10%\n",
      "Epoch 46/250, Loss: 12.5993, Accuracy: 26.96%\n",
      "Validation Loss: 2.7768, Validation Accuracy: 31.86%\n",
      "Epoch 47/250, Loss: 12.5472, Accuracy: 28.63%\n",
      "Validation Loss: 2.7070, Validation Accuracy: 32.65%\n",
      "Epoch 48/250, Loss: 12.4381, Accuracy: 30.39%\n",
      "Validation Loss: 2.7247, Validation Accuracy: 31.08%\n",
      "Epoch 49/250, Loss: 12.3713, Accuracy: 29.80%\n",
      "Validation Loss: 2.7294, Validation Accuracy: 33.24%\n",
      "Epoch 50/250, Loss: 12.3150, Accuracy: 28.43%\n",
      "Validation Loss: 2.7139, Validation Accuracy: 32.55%\n",
      "Epoch 51/250, Loss: 12.2492, Accuracy: 29.71%\n",
      "Validation Loss: 2.8058, Validation Accuracy: 30.98%\n",
      "Epoch 52/250, Loss: 12.0839, Accuracy: 32.35%\n",
      "Validation Loss: 2.6851, Validation Accuracy: 32.65%\n",
      "Epoch 53/250, Loss: 12.0771, Accuracy: 29.12%\n",
      "Validation Loss: 2.6778, Validation Accuracy: 33.14%\n",
      "Epoch 54/250, Loss: 11.9291, Accuracy: 34.71%\n",
      "Validation Loss: 2.7208, Validation Accuracy: 32.84%\n",
      "Epoch 55/250, Loss: 11.8928, Accuracy: 33.24%\n",
      "Validation Loss: 2.7402, Validation Accuracy: 31.27%\n",
      "Epoch 56/250, Loss: 11.8366, Accuracy: 30.78%\n",
      "Validation Loss: 2.6081, Validation Accuracy: 35.49%\n",
      "Epoch 57/250, Loss: 11.7514, Accuracy: 34.12%\n",
      "Validation Loss: 2.5782, Validation Accuracy: 36.08%\n",
      "Epoch 58/250, Loss: 11.7270, Accuracy: 34.80%\n",
      "Validation Loss: 2.5999, Validation Accuracy: 34.71%\n",
      "Epoch 59/250, Loss: 11.6143, Accuracy: 34.51%\n",
      "Validation Loss: 2.6317, Validation Accuracy: 33.92%\n",
      "Epoch 60/250, Loss: 11.5373, Accuracy: 33.63%\n",
      "Validation Loss: 2.5522, Validation Accuracy: 35.78%\n",
      "Epoch 61/250, Loss: 11.4534, Accuracy: 34.90%\n",
      "Validation Loss: 2.5722, Validation Accuracy: 35.39%\n",
      "Epoch 62/250, Loss: 11.4232, Accuracy: 35.49%\n",
      "Validation Loss: 2.5235, Validation Accuracy: 37.65%\n",
      "Epoch 63/250, Loss: 11.3445, Accuracy: 35.29%\n",
      "Validation Loss: 2.5393, Validation Accuracy: 34.90%\n",
      "Epoch 64/250, Loss: 11.2769, Accuracy: 39.71%\n",
      "Validation Loss: 2.4977, Validation Accuracy: 35.69%\n",
      "Epoch 65/250, Loss: 11.1940, Accuracy: 37.16%\n",
      "Validation Loss: 2.5663, Validation Accuracy: 35.98%\n",
      "Epoch 66/250, Loss: 11.0941, Accuracy: 37.25%\n",
      "Validation Loss: 2.4886, Validation Accuracy: 36.86%\n",
      "Epoch 67/250, Loss: 11.0947, Accuracy: 37.06%\n",
      "Validation Loss: 2.4596, Validation Accuracy: 37.94%\n",
      "Epoch 68/250, Loss: 11.0218, Accuracy: 38.43%\n",
      "Validation Loss: 2.5662, Validation Accuracy: 35.49%\n",
      "Epoch 69/250, Loss: 10.9132, Accuracy: 41.08%\n",
      "Validation Loss: 2.3816, Validation Accuracy: 39.51%\n",
      "Epoch 70/250, Loss: 10.8448, Accuracy: 39.41%\n",
      "Validation Loss: 2.4064, Validation Accuracy: 39.31%\n",
      "Epoch 71/250, Loss: 10.7713, Accuracy: 40.10%\n",
      "Validation Loss: 2.3956, Validation Accuracy: 39.61%\n",
      "Epoch 72/250, Loss: 10.7879, Accuracy: 38.82%\n",
      "Validation Loss: 2.3382, Validation Accuracy: 40.69%\n",
      "Epoch 73/250, Loss: 10.6614, Accuracy: 43.14%\n",
      "Validation Loss: 2.2958, Validation Accuracy: 42.25%\n",
      "Epoch 74/250, Loss: 10.6202, Accuracy: 43.14%\n",
      "Validation Loss: 2.4521, Validation Accuracy: 39.22%\n",
      "Epoch 75/250, Loss: 10.6235, Accuracy: 41.27%\n",
      "Validation Loss: 2.4607, Validation Accuracy: 39.12%\n",
      "Epoch 76/250, Loss: 10.6188, Accuracy: 39.51%\n",
      "Validation Loss: 2.4098, Validation Accuracy: 39.31%\n",
      "Epoch 77/250, Loss: 10.5497, Accuracy: 42.25%\n",
      "Validation Loss: 2.3027, Validation Accuracy: 41.57%\n",
      "Epoch 78/250, Loss: 10.4946, Accuracy: 42.45%\n",
      "Validation Loss: 2.2948, Validation Accuracy: 40.88%\n",
      "Epoch 79/250, Loss: 10.3904, Accuracy: 42.84%\n",
      "Validation Loss: 2.4657, Validation Accuracy: 37.65%\n",
      "Epoch 80/250, Loss: 10.3009, Accuracy: 43.92%\n",
      "Validation Loss: 2.3272, Validation Accuracy: 41.76%\n",
      "Epoch 81/250, Loss: 10.2504, Accuracy: 44.41%\n",
      "Validation Loss: 2.3160, Validation Accuracy: 41.37%\n",
      "Epoch 82/250, Loss: 10.2569, Accuracy: 41.57%\n",
      "Validation Loss: 2.3826, Validation Accuracy: 39.90%\n",
      "Epoch 83/250, Loss: 10.1293, Accuracy: 45.29%\n",
      "Validation Loss: 2.2892, Validation Accuracy: 41.47%\n",
      "Epoch 84/250, Loss: 10.0892, Accuracy: 44.90%\n",
      "Validation Loss: 2.2960, Validation Accuracy: 40.69%\n",
      "Epoch 85/250, Loss: 10.0462, Accuracy: 45.49%\n",
      "Validation Loss: 2.3605, Validation Accuracy: 38.43%\n",
      "Epoch 86/250, Loss: 10.0402, Accuracy: 46.08%\n",
      "Validation Loss: 2.2433, Validation Accuracy: 42.65%\n",
      "Epoch 87/250, Loss: 9.9949, Accuracy: 45.88%\n",
      "Validation Loss: 2.2876, Validation Accuracy: 41.57%\n",
      "Epoch 88/250, Loss: 9.9490, Accuracy: 43.63%\n",
      "Validation Loss: 2.3238, Validation Accuracy: 40.78%\n",
      "Epoch 89/250, Loss: 9.8373, Accuracy: 48.33%\n",
      "Validation Loss: 2.2307, Validation Accuracy: 45.78%\n",
      "Epoch 90/250, Loss: 9.8074, Accuracy: 48.73%\n",
      "Validation Loss: 2.1912, Validation Accuracy: 44.71%\n",
      "Epoch 91/250, Loss: 9.7800, Accuracy: 48.73%\n",
      "Validation Loss: 2.2515, Validation Accuracy: 42.94%\n",
      "Epoch 92/250, Loss: 9.7181, Accuracy: 47.55%\n",
      "Validation Loss: 2.2396, Validation Accuracy: 41.57%\n",
      "Epoch 93/250, Loss: 9.7265, Accuracy: 48.53%\n",
      "Validation Loss: 2.1975, Validation Accuracy: 43.04%\n",
      "Epoch 94/250, Loss: 9.6671, Accuracy: 47.84%\n",
      "Validation Loss: 2.1912, Validation Accuracy: 45.78%\n",
      "Epoch 95/250, Loss: 9.6404, Accuracy: 50.20%\n",
      "Validation Loss: 2.3551, Validation Accuracy: 40.88%\n",
      "Epoch 96/250, Loss: 9.5780, Accuracy: 49.31%\n",
      "Validation Loss: 2.1480, Validation Accuracy: 46.57%\n",
      "Epoch 97/250, Loss: 9.5199, Accuracy: 49.61%\n",
      "Validation Loss: 2.2638, Validation Accuracy: 40.78%\n",
      "Epoch 98/250, Loss: 9.5528, Accuracy: 47.45%\n",
      "Validation Loss: 2.1725, Validation Accuracy: 44.80%\n",
      "Epoch 99/250, Loss: 9.4408, Accuracy: 49.80%\n",
      "Validation Loss: 2.1713, Validation Accuracy: 45.59%\n",
      "Epoch 100/250, Loss: 9.3621, Accuracy: 51.96%\n",
      "Validation Loss: 2.1721, Validation Accuracy: 45.00%\n",
      "Epoch 101/250, Loss: 9.3374, Accuracy: 50.98%\n",
      "Validation Loss: 2.2431, Validation Accuracy: 42.55%\n",
      "Epoch 102/250, Loss: 9.2460, Accuracy: 53.92%\n",
      "Validation Loss: 2.1895, Validation Accuracy: 44.02%\n",
      "Epoch 103/250, Loss: 9.2715, Accuracy: 52.45%\n",
      "Validation Loss: 2.2079, Validation Accuracy: 44.41%\n",
      "Epoch 104/250, Loss: 9.2286, Accuracy: 52.75%\n",
      "Validation Loss: 2.2305, Validation Accuracy: 42.45%\n",
      "Epoch 105/250, Loss: 9.1818, Accuracy: 52.55%\n",
      "Validation Loss: 2.2061, Validation Accuracy: 42.55%\n",
      "Epoch 106/250, Loss: 9.1650, Accuracy: 52.55%\n",
      "Validation Loss: 2.1331, Validation Accuracy: 46.18%\n",
      "Epoch 107/250, Loss: 9.1318, Accuracy: 52.65%\n",
      "Validation Loss: 2.1696, Validation Accuracy: 44.61%\n",
      "Epoch 108/250, Loss: 9.0437, Accuracy: 54.02%\n",
      "Validation Loss: 2.1604, Validation Accuracy: 45.00%\n",
      "Epoch 109/250, Loss: 9.0298, Accuracy: 54.02%\n",
      "Validation Loss: 2.1051, Validation Accuracy: 47.16%\n",
      "Epoch 110/250, Loss: 8.9641, Accuracy: 53.14%\n",
      "Validation Loss: 1.9930, Validation Accuracy: 47.75%\n",
      "Epoch 111/250, Loss: 8.9480, Accuracy: 53.92%\n",
      "Validation Loss: 2.1928, Validation Accuracy: 44.90%\n",
      "Epoch 112/250, Loss: 8.9021, Accuracy: 54.71%\n",
      "Validation Loss: 2.0336, Validation Accuracy: 48.43%\n",
      "Epoch 113/250, Loss: 8.8396, Accuracy: 55.00%\n",
      "Validation Loss: 1.9903, Validation Accuracy: 49.41%\n",
      "Epoch 114/250, Loss: 8.8047, Accuracy: 55.49%\n",
      "Validation Loss: 1.9991, Validation Accuracy: 49.80%\n",
      "Epoch 115/250, Loss: 8.8218, Accuracy: 53.82%\n",
      "Validation Loss: 2.0513, Validation Accuracy: 48.82%\n",
      "Epoch 116/250, Loss: 8.7943, Accuracy: 54.12%\n",
      "Validation Loss: 2.2619, Validation Accuracy: 43.63%\n",
      "Epoch 117/250, Loss: 8.7489, Accuracy: 54.61%\n",
      "Validation Loss: 2.0610, Validation Accuracy: 47.84%\n",
      "Epoch 118/250, Loss: 8.7073, Accuracy: 56.37%\n",
      "Validation Loss: 2.0801, Validation Accuracy: 46.18%\n",
      "Epoch 119/250, Loss: 8.6657, Accuracy: 58.14%\n",
      "Validation Loss: 2.0872, Validation Accuracy: 45.78%\n",
      "Epoch 120/250, Loss: 8.6194, Accuracy: 58.53%\n",
      "Validation Loss: 2.0306, Validation Accuracy: 48.63%\n",
      "Epoch 121/250, Loss: 8.6101, Accuracy: 56.96%\n",
      "Validation Loss: 2.0616, Validation Accuracy: 49.90%\n",
      "Epoch 122/250, Loss: 8.5770, Accuracy: 55.88%\n",
      "Validation Loss: 1.9399, Validation Accuracy: 50.10%\n",
      "Epoch 123/250, Loss: 8.5196, Accuracy: 59.22%\n",
      "Validation Loss: 2.0081, Validation Accuracy: 48.82%\n",
      "Epoch 124/250, Loss: 8.5209, Accuracy: 57.75%\n",
      "Validation Loss: 2.0421, Validation Accuracy: 47.94%\n",
      "Epoch 125/250, Loss: 8.4743, Accuracy: 57.16%\n",
      "Validation Loss: 1.9541, Validation Accuracy: 51.37%\n",
      "Epoch 126/250, Loss: 8.4364, Accuracy: 58.82%\n",
      "Validation Loss: 2.0419, Validation Accuracy: 47.75%\n",
      "Epoch 127/250, Loss: 8.3548, Accuracy: 61.76%\n",
      "Validation Loss: 1.9336, Validation Accuracy: 51.67%\n",
      "Epoch 128/250, Loss: 8.2882, Accuracy: 62.65%\n",
      "Validation Loss: 2.0356, Validation Accuracy: 49.61%\n",
      "Epoch 129/250, Loss: 8.3453, Accuracy: 59.31%\n",
      "Validation Loss: 2.3163, Validation Accuracy: 42.94%\n",
      "Epoch 130/250, Loss: 8.3405, Accuracy: 58.33%\n",
      "Validation Loss: 2.0915, Validation Accuracy: 47.35%\n",
      "Epoch 131/250, Loss: 8.2569, Accuracy: 60.20%\n",
      "Validation Loss: 2.0587, Validation Accuracy: 47.94%\n",
      "Epoch 132/250, Loss: 8.2814, Accuracy: 58.82%\n",
      "Validation Loss: 1.9746, Validation Accuracy: 49.80%\n",
      "Epoch 133/250, Loss: 8.2363, Accuracy: 61.18%\n",
      "Validation Loss: 2.1097, Validation Accuracy: 47.65%\n",
      "Epoch 134/250, Loss: 8.2165, Accuracy: 59.80%\n",
      "Validation Loss: 2.0654, Validation Accuracy: 46.76%\n",
      "Epoch 135/250, Loss: 8.2219, Accuracy: 58.92%\n",
      "Validation Loss: 2.0143, Validation Accuracy: 49.61%\n",
      "Epoch 136/250, Loss: 8.1060, Accuracy: 60.69%\n",
      "Validation Loss: 2.0822, Validation Accuracy: 46.18%\n",
      "Epoch 137/250, Loss: 8.0430, Accuracy: 62.16%\n",
      "Validation Loss: 1.9801, Validation Accuracy: 49.02%\n",
      "Epoch 138/250, Loss: 8.0864, Accuracy: 61.86%\n",
      "Validation Loss: 2.0404, Validation Accuracy: 49.22%\n",
      "Epoch 139/250, Loss: 7.9557, Accuracy: 62.55%\n",
      "Validation Loss: 1.8390, Validation Accuracy: 53.82%\n",
      "Epoch 140/250, Loss: 7.9009, Accuracy: 67.45%\n",
      "Validation Loss: 1.8154, Validation Accuracy: 54.51%\n",
      "Epoch 141/250, Loss: 7.8757, Accuracy: 66.08%\n",
      "Validation Loss: 1.8075, Validation Accuracy: 55.39%\n",
      "Epoch 142/250, Loss: 7.8594, Accuracy: 68.43%\n",
      "Validation Loss: 1.8018, Validation Accuracy: 55.39%\n",
      "Epoch 143/250, Loss: 7.8670, Accuracy: 65.69%\n",
      "Validation Loss: 1.7940, Validation Accuracy: 55.49%\n",
      "Epoch 144/250, Loss: 7.8824, Accuracy: 64.90%\n",
      "Validation Loss: 1.8037, Validation Accuracy: 55.69%\n",
      "Epoch 145/250, Loss: 7.7979, Accuracy: 70.39%\n",
      "Validation Loss: 1.8118, Validation Accuracy: 55.69%\n",
      "Epoch 146/250, Loss: 7.8329, Accuracy: 66.86%\n",
      "Validation Loss: 1.8272, Validation Accuracy: 55.20%\n",
      "Epoch 147/250, Loss: 7.7869, Accuracy: 69.31%\n",
      "Validation Loss: 1.7823, Validation Accuracy: 56.18%\n",
      "Epoch 148/250, Loss: 7.8016, Accuracy: 68.33%\n",
      "Validation Loss: 1.7984, Validation Accuracy: 55.49%\n",
      "Epoch 149/250, Loss: 7.8118, Accuracy: 68.63%\n",
      "Validation Loss: 1.8035, Validation Accuracy: 55.49%\n",
      "Epoch 150/250, Loss: 7.8126, Accuracy: 68.82%\n",
      "Validation Loss: 1.8118, Validation Accuracy: 55.98%\n",
      "Epoch 151/250, Loss: 7.7579, Accuracy: 70.78%\n",
      "Validation Loss: 1.8141, Validation Accuracy: 55.78%\n",
      "Epoch 152/250, Loss: 7.7973, Accuracy: 67.94%\n",
      "Validation Loss: 1.7801, Validation Accuracy: 56.96%\n",
      "Epoch 153/250, Loss: 7.8239, Accuracy: 68.14%\n",
      "Validation Loss: 1.7794, Validation Accuracy: 56.76%\n",
      "Epoch 154/250, Loss: 7.7775, Accuracy: 68.82%\n",
      "Validation Loss: 1.7811, Validation Accuracy: 57.25%\n",
      "Epoch 155/250, Loss: 7.7556, Accuracy: 70.69%\n",
      "Validation Loss: 1.7819, Validation Accuracy: 55.59%\n",
      "Epoch 156/250, Loss: 7.7679, Accuracy: 68.53%\n",
      "Validation Loss: 1.8032, Validation Accuracy: 55.78%\n",
      "Epoch 157/250, Loss: 7.7763, Accuracy: 67.35%\n",
      "Validation Loss: 1.7746, Validation Accuracy: 56.37%\n",
      "Epoch 158/250, Loss: 7.7457, Accuracy: 68.73%\n",
      "Validation Loss: 1.7755, Validation Accuracy: 56.96%\n",
      "Epoch 159/250, Loss: 7.7615, Accuracy: 68.73%\n",
      "Validation Loss: 1.7768, Validation Accuracy: 56.08%\n",
      "Epoch 160/250, Loss: 7.7559, Accuracy: 70.49%\n",
      "Validation Loss: 1.7781, Validation Accuracy: 56.37%\n",
      "Epoch 161/250, Loss: 7.7204, Accuracy: 71.08%\n",
      "Validation Loss: 1.7627, Validation Accuracy: 57.35%\n",
      "Epoch 162/250, Loss: 7.7854, Accuracy: 67.55%\n",
      "Validation Loss: 1.7653, Validation Accuracy: 57.16%\n",
      "Epoch 163/250, Loss: 7.6898, Accuracy: 73.14%\n",
      "Validation Loss: 1.7750, Validation Accuracy: 57.25%\n",
      "Epoch 164/250, Loss: 7.7213, Accuracy: 70.39%\n",
      "Validation Loss: 1.7684, Validation Accuracy: 57.55%\n",
      "Epoch 165/250, Loss: 7.7130, Accuracy: 71.57%\n",
      "Validation Loss: 1.7526, Validation Accuracy: 56.86%\n",
      "Epoch 166/250, Loss: 7.7471, Accuracy: 70.10%\n",
      "Validation Loss: 1.7639, Validation Accuracy: 56.67%\n",
      "Epoch 167/250, Loss: 7.7339, Accuracy: 69.12%\n",
      "Validation Loss: 1.7593, Validation Accuracy: 57.84%\n",
      "Epoch 168/250, Loss: 7.6925, Accuracy: 71.57%\n",
      "Validation Loss: 1.7620, Validation Accuracy: 57.84%\n",
      "Epoch 169/250, Loss: 7.6825, Accuracy: 72.06%\n",
      "Validation Loss: 1.7715, Validation Accuracy: 56.67%\n",
      "Epoch 170/250, Loss: 7.7162, Accuracy: 69.12%\n",
      "Validation Loss: 1.7567, Validation Accuracy: 57.16%\n",
      "Epoch 171/250, Loss: 7.6686, Accuracy: 70.98%\n",
      "Validation Loss: 1.7648, Validation Accuracy: 56.47%\n",
      "Epoch 172/250, Loss: 7.6353, Accuracy: 73.14%\n",
      "Validation Loss: 1.7584, Validation Accuracy: 57.06%\n",
      "Epoch 173/250, Loss: 7.6992, Accuracy: 70.10%\n",
      "Validation Loss: 1.7501, Validation Accuracy: 57.84%\n",
      "Epoch 174/250, Loss: 7.7093, Accuracy: 70.10%\n",
      "Validation Loss: 1.7456, Validation Accuracy: 57.45%\n",
      "Epoch 175/250, Loss: 7.7190, Accuracy: 69.12%\n",
      "Validation Loss: 1.7559, Validation Accuracy: 57.06%\n",
      "Epoch 176/250, Loss: 7.6352, Accuracy: 73.92%\n",
      "Validation Loss: 1.7646, Validation Accuracy: 56.67%\n",
      "Epoch 177/250, Loss: 7.6684, Accuracy: 72.25%\n",
      "Validation Loss: 1.7564, Validation Accuracy: 57.75%\n",
      "Epoch 178/250, Loss: 7.6235, Accuracy: 73.92%\n",
      "Validation Loss: 1.7438, Validation Accuracy: 58.04%\n",
      "Epoch 179/250, Loss: 7.6383, Accuracy: 72.75%\n",
      "Validation Loss: 1.7741, Validation Accuracy: 56.27%\n",
      "Epoch 180/250, Loss: 7.6154, Accuracy: 73.24%\n",
      "Validation Loss: 1.7541, Validation Accuracy: 57.84%\n",
      "Epoch 181/250, Loss: 7.6706, Accuracy: 70.78%\n",
      "Validation Loss: 1.7431, Validation Accuracy: 57.75%\n",
      "Epoch 182/250, Loss: 7.6220, Accuracy: 72.94%\n",
      "Validation Loss: 1.7444, Validation Accuracy: 57.55%\n",
      "Epoch 183/250, Loss: 7.6195, Accuracy: 71.96%\n",
      "Validation Loss: 1.7302, Validation Accuracy: 58.43%\n",
      "Epoch 184/250, Loss: 7.6324, Accuracy: 71.67%\n",
      "Validation Loss: 1.7415, Validation Accuracy: 57.65%\n",
      "Epoch 185/250, Loss: 7.5726, Accuracy: 74.31%\n",
      "Validation Loss: 1.7423, Validation Accuracy: 58.04%\n",
      "Epoch 186/250, Loss: 7.6462, Accuracy: 70.00%\n",
      "Validation Loss: 1.7441, Validation Accuracy: 58.43%\n",
      "Epoch 187/250, Loss: 7.6542, Accuracy: 69.90%\n",
      "Validation Loss: 1.7373, Validation Accuracy: 58.14%\n",
      "Epoch 188/250, Loss: 7.6618, Accuracy: 69.51%\n",
      "Validation Loss: 1.7520, Validation Accuracy: 57.65%\n",
      "Epoch 189/250, Loss: 7.6260, Accuracy: 71.67%\n",
      "Validation Loss: 1.7499, Validation Accuracy: 57.94%\n",
      "Epoch 190/250, Loss: 7.6146, Accuracy: 72.35%\n",
      "Validation Loss: 1.7422, Validation Accuracy: 58.04%\n",
      "Epoch 191/250, Loss: 7.5964, Accuracy: 71.37%\n",
      "Validation Loss: 1.7404, Validation Accuracy: 57.55%\n",
      "Epoch 192/250, Loss: 7.6222, Accuracy: 70.29%\n",
      "Validation Loss: 1.7452, Validation Accuracy: 58.04%\n",
      "Epoch 193/250, Loss: 7.6216, Accuracy: 70.39%\n",
      "Validation Loss: 1.7410, Validation Accuracy: 58.14%\n",
      "Epoch 194/250, Loss: 7.5903, Accuracy: 72.84%\n",
      "Validation Loss: 1.7425, Validation Accuracy: 57.45%\n",
      "Epoch 195/250, Loss: 7.5630, Accuracy: 73.04%\n",
      "Validation Loss: 1.7302, Validation Accuracy: 58.92%\n",
      "Epoch 196/250, Loss: 7.6011, Accuracy: 72.65%\n",
      "Validation Loss: 1.7349, Validation Accuracy: 58.33%\n",
      "Epoch 197/250, Loss: 7.6169, Accuracy: 69.80%\n",
      "Validation Loss: 1.7265, Validation Accuracy: 59.02%\n",
      "Epoch 198/250, Loss: 7.5847, Accuracy: 73.43%\n",
      "Validation Loss: 1.7279, Validation Accuracy: 59.02%\n",
      "Epoch 199/250, Loss: 7.5578, Accuracy: 72.75%\n",
      "Validation Loss: 1.7302, Validation Accuracy: 59.12%\n",
      "Epoch 200/250, Loss: 7.5713, Accuracy: 71.86%\n",
      "Validation Loss: 1.7324, Validation Accuracy: 59.02%\n",
      "Epoch 201/250, Loss: 7.5436, Accuracy: 73.53%\n",
      "Validation Loss: 1.7312, Validation Accuracy: 58.82%\n",
      "Epoch 202/250, Loss: 7.5712, Accuracy: 72.45%\n",
      "Validation Loss: 1.7274, Validation Accuracy: 58.73%\n",
      "Epoch 203/250, Loss: 7.6074, Accuracy: 71.57%\n",
      "Validation Loss: 1.7239, Validation Accuracy: 59.12%\n",
      "Epoch 204/250, Loss: 7.5906, Accuracy: 72.55%\n",
      "Validation Loss: 1.7237, Validation Accuracy: 59.12%\n",
      "Epoch 205/250, Loss: 7.5338, Accuracy: 74.90%\n",
      "Validation Loss: 1.7226, Validation Accuracy: 59.22%\n",
      "Epoch 206/250, Loss: 7.5593, Accuracy: 73.33%\n",
      "Validation Loss: 1.7272, Validation Accuracy: 58.92%\n",
      "Epoch 207/250, Loss: 7.5605, Accuracy: 72.25%\n",
      "Validation Loss: 1.7250, Validation Accuracy: 59.12%\n",
      "Epoch 208/250, Loss: 7.5561, Accuracy: 73.53%\n",
      "Validation Loss: 1.7253, Validation Accuracy: 58.73%\n",
      "Epoch 209/250, Loss: 7.5938, Accuracy: 70.29%\n",
      "Validation Loss: 1.7291, Validation Accuracy: 58.92%\n",
      "Epoch 210/250, Loss: 7.5635, Accuracy: 73.73%\n",
      "Validation Loss: 1.7310, Validation Accuracy: 58.73%\n",
      "Epoch 211/250, Loss: 7.5812, Accuracy: 71.27%\n",
      "Validation Loss: 1.7227, Validation Accuracy: 58.92%\n",
      "Epoch 212/250, Loss: 7.5891, Accuracy: 72.65%\n",
      "Validation Loss: 1.7307, Validation Accuracy: 58.53%\n",
      "Epoch 213/250, Loss: 7.5699, Accuracy: 72.65%\n",
      "Validation Loss: 1.7245, Validation Accuracy: 58.73%\n",
      "Epoch 214/250, Loss: 7.5351, Accuracy: 75.49%\n",
      "Validation Loss: 1.7252, Validation Accuracy: 58.43%\n",
      "Epoch 215/250, Loss: 7.5389, Accuracy: 73.63%\n",
      "Validation Loss: 1.7246, Validation Accuracy: 58.82%\n",
      "Epoch 216/250, Loss: 7.5599, Accuracy: 73.43%\n",
      "Validation Loss: 1.7239, Validation Accuracy: 58.73%\n",
      "Epoch 217/250, Loss: 7.5534, Accuracy: 73.82%\n",
      "Validation Loss: 1.7260, Validation Accuracy: 58.73%\n",
      "Epoch 218/250, Loss: 7.6307, Accuracy: 69.31%\n",
      "Validation Loss: 1.7281, Validation Accuracy: 58.73%\n",
      "Epoch 219/250, Loss: 7.6007, Accuracy: 72.55%\n",
      "Validation Loss: 1.7257, Validation Accuracy: 58.63%\n",
      "Epoch 220/250, Loss: 7.5786, Accuracy: 72.25%\n",
      "Validation Loss: 1.7226, Validation Accuracy: 59.12%\n",
      "Early stopping at epoch 219\n",
      "Best accuracy on validation split: 59.21568627450981 at epoch 204\n",
      "Accuracy on testing set: 52.34997560578956 %\n",
      "Accuracy of 0 : 55.0 %\n",
      "Accuracy of 1 : 65.0 %\n",
      "Accuracy of 2 : 10.0 %\n",
      "Accuracy of 3 : 27.77777777777778 %\n",
      "Accuracy of 4 : 48.888888888888886 %\n",
      "Accuracy of 5 : 32.0 %\n",
      "Accuracy of 6 : 65.0 %\n",
      "Accuracy of 7 : 78.46153846153847 %\n",
      "Accuracy of 8 : 69.23076923076923 %\n",
      "Accuracy of 9 : 80.0 %\n",
      "Accuracy of 10 : 14.925373134328359 %\n",
      "Accuracy of 11 : 56.71641791044776 %\n",
      "Accuracy of 12 : 72.41379310344827 %\n",
      "Accuracy of 13 : 78.57142857142857 %\n",
      "Accuracy of 14 : 44.827586206896555 %\n",
      "Accuracy of 15 : 33.333333333333336 %\n",
      "Accuracy of 16 : 67.6923076923077 %\n",
      "Accuracy of 17 : 20.967741935483872 %\n",
      "Accuracy of 18 : 27.586206896551722 %\n",
      "Accuracy of 19 : 55.55555555555556 %\n",
      "Accuracy of 20 : 60.0 %\n",
      "Accuracy of 21 : 76.92307692307692 %\n",
      "Accuracy of 22 : 40.84507042253521 %\n",
      "Accuracy of 23 : 45.45454545454545 %\n",
      "Accuracy of 24 : 80.95238095238095 %\n",
      "Accuracy of 25 : 47.61904761904762 %\n",
      "Accuracy of 26 : 75.0 %\n",
      "Accuracy of 27 : 58.69565217391305 %\n",
      "Accuracy of 28 : 67.24137931034483 %\n",
      "Accuracy of 29 : 38.46153846153846 %\n",
      "Accuracy of 30 : 28.125 %\n",
      "Accuracy of 31 : 0.0 %\n",
      "Accuracy of 32 : 53.84615384615385 %\n",
      "Accuracy of 33 : 50.0 %\n",
      "Accuracy of 34 : 86.95652173913044 %\n",
      "Accuracy of 35 : 56.36363636363637 %\n",
      "Accuracy of 36 : 94.31818181818181 %\n",
      "Accuracy of 37 : 61.111111111111114 %\n",
      "Accuracy of 38 : 28.571428571428573 %\n",
      "Accuracy of 39 : 51.06382978723404 %\n",
      "Accuracy of 40 : 38.3177570093458 %\n",
      "Accuracy of 41 : 33.333333333333336 %\n",
      "Accuracy of 42 : 8.181818181818182 %\n",
      "Accuracy of 43 : 43.83561643835616 %\n",
      "Accuracy of 44 : 55.0 %\n",
      "Accuracy of 45 : 80.68181818181819 %\n",
      "Accuracy of 46 : 91.48936170212765 %\n",
      "Accuracy of 47 : 45.09803921568628 %\n",
      "Accuracy of 48 : 96.55172413793103 %\n",
      "Accuracy of 49 : 79.16666666666667 %\n",
      "Accuracy of 50 : 26.89075630252101 %\n",
      "Accuracy of 51 : 70.76923076923077 %\n",
      "Accuracy of 52 : 26.027397260273972 %\n",
      "Accuracy of 53 : 82.92682926829268 %\n",
      "Accuracy of 54 : 74.50980392156863 %\n",
      "Accuracy of 55 : 82.02247191011236 %\n",
      "Accuracy of 56 : 70.2127659574468 %\n",
      "Accuracy of 57 : 82.97872340425532 %\n",
      "Accuracy of 58 : 72.34042553191489 %\n",
      "Accuracy of 59 : 85.3932584269663 %\n",
      "Accuracy of 60 : 96.66666666666667 %\n",
      "Accuracy of 61 : 22.857142857142858 %\n",
      "Accuracy of 62 : 100.0 %\n",
      "Accuracy of 63 : 96.875 %\n",
      "Accuracy of 64 : 56.09756097560975 %\n",
      "Accuracy of 65 : 90.2439024390244 %\n",
      "Accuracy of 66 : 31.818181818181817 %\n",
      "Accuracy of 67 : 52.94117647058823 %\n",
      "Accuracy of 68 : 82.3529411764706 %\n",
      "Accuracy of 69 : 71.42857142857143 %\n",
      "Accuracy of 70 : 74.13793103448276 %\n",
      "Accuracy of 71 : 25.0 %\n",
      "Accuracy of 72 : 44.252873563218394 %\n",
      "Accuracy of 73 : 45.6953642384106 %\n",
      "Accuracy of 74 : 64.0 %\n",
      "Accuracy of 75 : 62.06896551724138 %\n",
      "Accuracy of 76 : 67.53246753246754 %\n",
      "Accuracy of 77 : 34.18803418803419 %\n",
      "Accuracy of 78 : 85.71428571428571 %\n",
      "Accuracy of 79 : 28.235294117647058 %\n",
      "Accuracy of 80 : 72.6027397260274 %\n",
      "Accuracy of 81 : 43.47826086956522 %\n",
      "Accuracy of 82 : 30.63063063063063 %\n",
      "Accuracy of 83 : 21.21212121212121 %\n",
      "Accuracy of 84 : 62.7906976744186 %\n",
      "Accuracy of 85 : 63.1578947368421 %\n",
      "Accuracy of 86 : 65.11627906976744 %\n",
      "Accuracy of 87 : 31.34328358208955 %\n",
      "Accuracy of 88 : 50.0 %\n",
      "Accuracy of 89 : 19.35483870967742 %\n",
      "Accuracy of 90 : 35.714285714285715 %\n",
      "Accuracy of 91 : 80.43478260869566 %\n",
      "Accuracy of 92 : 34.61538461538461 %\n",
      "Accuracy of 93 : 33.098591549295776 %\n",
      "Accuracy of 94 : 27.77777777777778 %\n",
      "Accuracy of 95 : 23.943661971830984 %\n",
      "Accuracy of 96 : 28.26086956521739 %\n",
      "Accuracy of 97 : 41.935483870967744 %\n",
      "Accuracy of 98 : 58.13953488372093 %\n",
      "Accuracy of 99 : 75.86206896551724 %\n",
      "Accuracy of 100 : 21.05263157894737 %\n",
      "Accuracy of 101 : 71.42857142857143 %\n"
     ]
    }
   ],
   "source": [
    "best_accuracy_epoch = 0\n",
    "best_accuracy = 0\n",
    "early_stopping_patience = 15\n",
    "no_improve_epochs = 0\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader, 0):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        label_pred = model(images)\n",
    "        loss = criterion(label_pred, labels)\n",
    "        \n",
    "        # Manually add L2 regularization\n",
    "        l2_loss = 0\n",
    "        for param in model.parameters():\n",
    "            l2_loss += torch.sum(torch.pow(param, 2))\n",
    "        loss += 0.01 * l2_loss  # L2 regularization term\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = label_pred.max(1)\n",
    "        # predicted = torch.max(label_pred, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        batch_corr = (predicted == labels).sum()\n",
    "        batch_acc = batch_corr.item() / len(images)\n",
    "        \n",
    "        \n",
    "        # print(f\"Epoch Number {epoch}, Index = {i}/{len(train_loader)-1}, Loss = {loss.item()}\")\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "    \n",
    "    val_epoch_loss, val_epoch_acc = NetworkAccuracyOnValidation()\n",
    "    print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.2f}%')\n",
    "    \n",
    "    scheduler.step(val_epoch_loss)\n",
    "    \n",
    "    if (val_epoch_acc > best_accuracy):\n",
    "        best_accuracy = val_epoch_acc\n",
    "        best_accuracy_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "print(f\"Best accuracy on validation split: {best_accuracy} at epoch {best_accuracy_epoch}\")\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "NetworkAccuracyOnTesting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set: 52.34997560578956 %\n",
      "Accuracy of 0 : 55.0 %\n",
      "Accuracy of 1 : 65.0 %\n",
      "Accuracy of 2 : 10.0 %\n",
      "Accuracy of 3 : 27.77777777777778 %\n",
      "Accuracy of 4 : 48.888888888888886 %\n",
      "Accuracy of 5 : 32.0 %\n",
      "Accuracy of 6 : 65.0 %\n",
      "Accuracy of 7 : 78.46153846153847 %\n",
      "Accuracy of 8 : 69.23076923076923 %\n",
      "Accuracy of 9 : 80.0 %\n",
      "Accuracy of 10 : 14.925373134328359 %\n",
      "Accuracy of 11 : 56.71641791044776 %\n",
      "Accuracy of 12 : 72.41379310344827 %\n",
      "Accuracy of 13 : 78.57142857142857 %\n",
      "Accuracy of 14 : 44.827586206896555 %\n",
      "Accuracy of 15 : 33.333333333333336 %\n",
      "Accuracy of 16 : 67.6923076923077 %\n",
      "Accuracy of 17 : 20.967741935483872 %\n",
      "Accuracy of 18 : 27.586206896551722 %\n",
      "Accuracy of 19 : 55.55555555555556 %\n",
      "Accuracy of 20 : 60.0 %\n",
      "Accuracy of 21 : 76.92307692307692 %\n",
      "Accuracy of 22 : 40.84507042253521 %\n",
      "Accuracy of 23 : 45.45454545454545 %\n",
      "Accuracy of 24 : 80.95238095238095 %\n",
      "Accuracy of 25 : 47.61904761904762 %\n",
      "Accuracy of 26 : 75.0 %\n",
      "Accuracy of 27 : 58.69565217391305 %\n",
      "Accuracy of 28 : 67.24137931034483 %\n",
      "Accuracy of 29 : 38.46153846153846 %\n",
      "Accuracy of 30 : 28.125 %\n",
      "Accuracy of 31 : 0.0 %\n",
      "Accuracy of 32 : 53.84615384615385 %\n",
      "Accuracy of 33 : 50.0 %\n",
      "Accuracy of 34 : 86.95652173913044 %\n",
      "Accuracy of 35 : 56.36363636363637 %\n",
      "Accuracy of 36 : 94.31818181818181 %\n",
      "Accuracy of 37 : 61.111111111111114 %\n",
      "Accuracy of 38 : 28.571428571428573 %\n",
      "Accuracy of 39 : 51.06382978723404 %\n",
      "Accuracy of 40 : 38.3177570093458 %\n",
      "Accuracy of 41 : 33.333333333333336 %\n",
      "Accuracy of 42 : 8.181818181818182 %\n",
      "Accuracy of 43 : 43.83561643835616 %\n",
      "Accuracy of 44 : 55.0 %\n",
      "Accuracy of 45 : 80.68181818181819 %\n",
      "Accuracy of 46 : 91.48936170212765 %\n",
      "Accuracy of 47 : 45.09803921568628 %\n",
      "Accuracy of 48 : 96.55172413793103 %\n",
      "Accuracy of 49 : 79.16666666666667 %\n",
      "Accuracy of 50 : 26.89075630252101 %\n",
      "Accuracy of 51 : 70.76923076923077 %\n",
      "Accuracy of 52 : 26.027397260273972 %\n",
      "Accuracy of 53 : 82.92682926829268 %\n",
      "Accuracy of 54 : 74.50980392156863 %\n",
      "Accuracy of 55 : 82.02247191011236 %\n",
      "Accuracy of 56 : 70.2127659574468 %\n",
      "Accuracy of 57 : 82.97872340425532 %\n",
      "Accuracy of 58 : 72.34042553191489 %\n",
      "Accuracy of 59 : 85.3932584269663 %\n",
      "Accuracy of 60 : 96.66666666666667 %\n",
      "Accuracy of 61 : 22.857142857142858 %\n",
      "Accuracy of 62 : 100.0 %\n",
      "Accuracy of 63 : 96.875 %\n",
      "Accuracy of 64 : 56.09756097560975 %\n",
      "Accuracy of 65 : 90.2439024390244 %\n",
      "Accuracy of 66 : 31.818181818181817 %\n",
      "Accuracy of 67 : 52.94117647058823 %\n",
      "Accuracy of 68 : 82.3529411764706 %\n",
      "Accuracy of 69 : 71.42857142857143 %\n",
      "Accuracy of 70 : 74.13793103448276 %\n",
      "Accuracy of 71 : 25.0 %\n",
      "Accuracy of 72 : 44.252873563218394 %\n",
      "Accuracy of 73 : 45.6953642384106 %\n",
      "Accuracy of 74 : 64.0 %\n",
      "Accuracy of 75 : 62.06896551724138 %\n",
      "Accuracy of 76 : 67.53246753246754 %\n",
      "Accuracy of 77 : 34.18803418803419 %\n",
      "Accuracy of 78 : 85.71428571428571 %\n",
      "Accuracy of 79 : 28.235294117647058 %\n",
      "Accuracy of 80 : 72.6027397260274 %\n",
      "Accuracy of 81 : 43.47826086956522 %\n",
      "Accuracy of 82 : 30.63063063063063 %\n",
      "Accuracy of 83 : 21.21212121212121 %\n",
      "Accuracy of 84 : 62.7906976744186 %\n",
      "Accuracy of 85 : 63.1578947368421 %\n",
      "Accuracy of 86 : 65.11627906976744 %\n",
      "Accuracy of 87 : 31.34328358208955 %\n",
      "Accuracy of 88 : 50.0 %\n",
      "Accuracy of 89 : 19.35483870967742 %\n",
      "Accuracy of 90 : 35.714285714285715 %\n",
      "Accuracy of 91 : 80.43478260869566 %\n",
      "Accuracy of 92 : 34.61538461538461 %\n",
      "Accuracy of 93 : 33.098591549295776 %\n",
      "Accuracy of 94 : 27.77777777777778 %\n",
      "Accuracy of 95 : 23.943661971830984 %\n",
      "Accuracy of 96 : 28.26086956521739 %\n",
      "Accuracy of 97 : 41.935483870967744 %\n",
      "Accuracy of 98 : 58.13953488372093 %\n",
      "Accuracy of 99 : 75.86206896551724 %\n",
      "Accuracy of 100 : 21.05263157894737 %\n",
      "Accuracy of 101 : 71.42857142857143 %\n"
     ]
    }
   ],
   "source": [
    "NetworkAccuracyOnTesting()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

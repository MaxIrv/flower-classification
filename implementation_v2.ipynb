{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.0004\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Datasets and setup the Data Loaders (with data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_normal = transforms.Compose([\n",
    "    transforms.Resize((250, 250)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((250, 250)),\n",
    "    # Randomly change the brightness of the image\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    # Randomly flip the image horizontally\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),  # Randomly flip the image vertically\n",
    "    transforms.RandomRotation(55),  # Randomly rotate the image by 45 degrees\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean = [0.0, 0.0, 0.0], std = [1.0, 1.0, 1.0]) # Takes each value for the channel, subtracts the mean and divides by the standard deviation (value - mean) / std\n",
    "])\n",
    "\n",
    "# Define the transformations\n",
    "transformations1 = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Resize((250, 250))])\n",
    "\n",
    "# Load the dataset\n",
    "training_dataset = torchvision.datasets.Flowers102(root='./data', split=\"train\",\n",
    "                                                   download=True, transform=transform_train)\n",
    "testing_dataset = torchvision.datasets.Flowers102(root='./data', split=\"test\",\n",
    "                                                  download=True, transform=transformations1)\n",
    "validation_dataset = torchvision.datasets.Flowers102(root='./data', split=\"val\",\n",
    "                                                     download=True, transform=transformations1)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.relu = nn.PReLU()\n",
    "    \n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer4 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer5 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.layer6 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=(1,1), padding=(1,1)),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    \n",
    "    # self.fc1 = nn.Linear(256 * 3 * 3, 1024)\n",
    "    self.fc1 = nn.Linear(256 * 3 * 3, 102)\n",
    "    self.drop = nn.Dropout(p=0.25)\n",
    "    self.fc2 = nn.Linear(1024, 256)\n",
    "    self.fc3 = nn.Linear(256, 102)  # Output layer for 102 classes\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "    x = self.layer5(x)\n",
    "    x = self.layer6(x)\n",
    "    \n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    # x = self.relu(x)\n",
    "    # x = self.drop(x)\n",
    "    # x = self.fc2(x)\n",
    "    # x = self.relu(x)\n",
    "    # x = self.fc3(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Accuracy Tests (Validation and Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NetworkAccuracyOnValidation():\n",
    "    with torch.no_grad():\n",
    "        num_class_correct = [0 for i in range(102)]\n",
    "        num_class_samples = [0 for i in range(102)]\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for images, labels in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predictions[i]\n",
    "                if label == pred:\n",
    "                    num_class_correct[label] += 1\n",
    "                num_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * total_correct / total_samples\n",
    "        # print(f'Accuracy on validation set: {acc} %')\n",
    "        return acc\n",
    "\n",
    "\n",
    "def NetworkAccuracyOnTesting():\n",
    "    with torch.no_grad():\n",
    "        num_class_correct = [0 for i in range(102)]\n",
    "        num_class_samples = [0 for i in range(102)]\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predictions[i]\n",
    "                if (label == pred):\n",
    "                    num_class_correct[label] += 1\n",
    "                num_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * total_correct / total_samples\n",
    "        print(f'Accuracy on testing set: {acc} %')\n",
    "\n",
    "        for i in range(102):\n",
    "            acc = 100.0 * num_class_correct[i] / num_class_samples[i]\n",
    "            print(f'Accuracy of {i} : {acc} %')\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number 0, Loss = 4.204793930053711, Accuracy = 7.1568627450980395\n",
      "Epoch Number 1, Loss = 3.6936440467834473, Accuracy = 12.058823529411764\n",
      "Epoch Number 2, Loss = 3.5107157230377197, Accuracy = 16.176470588235293\n",
      "Epoch Number 3, Loss = 3.059312343597412, Accuracy = 18.529411764705884\n",
      "Epoch Number 4, Loss = 2.471863031387329, Accuracy = 20.980392156862745\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(label_pred, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m batch_corr \u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 15\u001b[0m batch_acc \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_corr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(images)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_accuracy_epoch = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader, 0):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        label_pred = model(images)\n",
    "        loss = criterion(label_pred, labels)\n",
    "        \n",
    "        predicted = torch.max(label_pred, 1)[1]\n",
    "        batch_corr = (predicted == labels).sum()\n",
    "        batch_acc = batch_corr.item() / len(images)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print(f\"Epoch Number {epoch}, Index = {i}/{len(train_loader)-1}, Loss = {loss.item()}\")\n",
    "        \n",
    "    scheduler.step()\n",
    "    current_accuracy = NetworkAccuracyOnValidation()\n",
    "    print(f\"Epoch Number {epoch}, Loss = {loss.item()}, Accuracy = {current_accuracy}\")\n",
    "    if (current_accuracy > best_accuracy):\n",
    "        best_accuracy = current_accuracy\n",
    "        best_accuracy_epoch = epoch\n",
    "        \n",
    "print(f\"Best accuracy on validation split: {best_accuracy} at epoch {best_accuracy_epoch}\")\n",
    "model.eval()\n",
    "NetworkAccuracyOnTesting()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
